{
  "hash": "b57e6d60d0c411b67500aae9070b6501",
  "result": {
    "markdown": "---\ntitle: \"Detecting Stable Diffusion Generated People\"\ndescription: \"A Deployed Proof-of-Concept\"\nauthor: \"Michael Mullarkey\"\ndate: \"2022-11-21\"\nformat: \n  html:\n    code-fold: true\n    toc: true\ncategories: [Trust and Safety, Python, Stable Diffusion]\nengine: knitr\nimage: sd_test_image_3.jpg\n---\n\n\n# Topline Summary\n\nAI can generate realistic-looking fake people, Stable Diffusion makes that easier than ever, and I've [deployed a model you can try yourself](https://huggingface.co/spaces/mcmullarkey/did_stable_diffusion_make_this_person){target=\"_blank\"} with 93% out-of-sample accuracy in detecting whether the person was generated by Stable Diffusion.\n\n# AI Can Generate Realistic Looking Faces\n\n[thispersondoesnotexist.com](https://thispersondoesnotexist.com/){target=\"_blank\"} [blew](https://www.theverge.com/tldr/2019/2/15/18226005/ai-generated-fake-people-portraits-thispersondoesnotexist-stylegan){target=\"_blank\"} [everyone](https://www.cnn.com/2019/02/28/tech/ai-fake-faces/index.html){target=\"_blank\"} [away](https://www.bbc.com/news/technology-47296481){target=\"_blank\"} when it first launched in 2019. The website would generate a brand new,^[Or almost brand new, if you refresh the site enough you definitely get repeats] entirely fabricated person each time you refreshed.<br>\n<br>\n![GAN Example Image](gan_example_image.jpg)\n<br>\n<br>\nThe site used GAN neural networks, and provided code templates for generating your own fake people. Some folks pointed out [at the time](https://venturebeat.com/media/why-thispersondoesnotexist-and-its-copycats-need-to-be-restricted/){target=\"_blank\"} that providing these code templates could have negative consequences. <br>\n<br>\n\n# Negative Side Effects Abound\n\nFor example, a network of bots using GAN-generated pictures [boosted tweets by a pro-secessionist candidate](https://twitter.com/conspirator0/status/1457049273971916802?t=s4r6fIRv7bXWSBJdaQcXqQ&s=19){target=\"_blank\"} for lieutenant governor in Texas. And that's [far from the only](https://mobile.twitter.com/conspirator0/status/1322704400226394112){target=\"_blank\"} swarm of bots that looked more like real people by using GAN generated faces. <br>\n<br>\nWhile these GAN-generated faces look realistic, they have some telltale visual cues that can help distinguish them from genuine photos. For example, GAN-generated faces tend to [render the eyes in the exact same position](https://twitter.com/conspirator0/status/1457051603773575168){target=\"_blank\"}. So while they might be tricky to spot, we've [gotten better](https://github.com/andreacos/gan-generated-face-detection){target=\"_blank\"} at screening for them.^[Though newer generations of GAN-generated faces will likely make them even harder to detect, see https://nvlabs.github.io/stylegan3/] <br>\n<br>\nEnter [Stable Diffusion](https://huggingface.co/spaces/stabilityai/stable-diffusion){target=\"_blank\"}.<br>\n<br>\n\n# The Potential for Negative Side Effects Only Increases with Stable Diffusion\nIn order to create a lot of faces using a GAN, you had to either manually refresh thispersondoesnotexist.com a bunch of times or know how to code. Generating realistic looking faces using Stable Diffusion is much simpler.<br>\n<br>\nIf you haven't heard of Stable Diffusion, it's a AI model that can convert text prompts like \"A cute penguin in front of a giant stack of pancakes, shot on iPhone\" into an image like this. <br>\n<br>\n![An excellent penguin](updated_penguin.jpg)\n<br>\n<br>\nYou can also write other kinds of prompts^[Which I won't be sharing here, more on that later!] that generate realistic looking people. There are few, if any, telltale visual cues that the images were generated by Stable Diffusion.<br>\n<br>\nThis person does not exist <br>\n<br>\n![This person does not exist](sd_test_image_3.jpg)\n<br>\n<br>\nNeither does this person <br>\n<br>\n![And neither does this person](sd_example_image_4.jpg)\n<br>\n<br>\nAnd they don't either.<br>\n<br>\n![And they don't either](sd_example_image_6.jpg)\n<br>\n<br>\n\n# I Built and Deployed a Model to Detect Whether People Were Generated by Stable Diffusion\n\nYou can find the deployed model [here](https://huggingface.co/spaces/mcmullarkey/did_stable_diffusion_make_this_person){target=\"_blank\"}. It predicts all of the example images correctly,^[Huge shout out to HuggingFace spaces + Gradio for making such a great interface for push-button model deployments] and the model has 93% out-of-sample accuracy with an out-of-sample F1 score of 0.88.<br>\n<br>\n![Here's an example of testing an image in the deployed model](image_deployed_model.png)\n<br>\n<br>\nYou can test the model with any real or Stable-Diffusion generated images you'd like using the deployed model. Please send interesting model successes + failures to me on [Twitter](https://mobile.twitter.com/mcmullarkey){target=\"_blank\"} or [Mastodon](https://data-folks.masto.host/@mcmullarkey){target=\"_blank\"}! <br>\n<br>\nThis is an initial proof-of-concept, so please don't use this as part of any production products. If you're interested in building on this idea I'd love to hear from you! \n\n# How Did You Build This Model?\n\nI had a lot of fun building this model using Python, PyTorch, and the fastai wrapper. I got to do a lot of interesting work with APIs, loops, and query optimization. <br>\n<br>\nIn huge contrast to most of my projects, I'm not going to publicly share my code. I don't want to provide a direct blueprint for how to programmatically generate a lot of realistic-looking fake people. I'm kind of bummed, because I think it's some of the best Python programming I've done. And I still think it's the right thing to do.<br>\n<br>\nI understand that folks have a variety of opinions about this, and I think the potential harms outweigh any potential benefits.^[Especially since we know people have used open-source fake people generators for ill already, the risk isn't hypothetical!]<br>\n<br>\nIf you want to get a sense of how I generally approached my model-building, I'd recommend you check out [Practical Deep Learning for Coders](https://course.fast.ai/){target=\"_blank\"}.\n\n# Conclusion\n\nI think Stable Diffusion is a powerful resource, and I think we need to think carefully about how to wield that power. Building models that can help detect whether an image was generated by Stable Diffusion is not a silver bullet answer. I think pervasive believable yet false imagery is a problem that far exceeds any one technical solution. <br>\n<br>\nAnd as we grapple with the proliferation of models like Stable Diffusion, having some technical tools like this model in our toolbelt feels like a good bet.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}