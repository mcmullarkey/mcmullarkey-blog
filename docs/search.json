[
  {
    "objectID": "posts/2022_11_06_duckdb_adventures/index.html",
    "href": "posts/2022_11_06_duckdb_adventures/index.html",
    "title": "Exploring My Twitter Archive with DuckDB and Python",
    "section": "",
    "text": "Load Packages\nFirst we’ll import the packages we need. If you want to skip the local timezone wrangling part you can eliminate the datetime, pytz, and tzlocal dependencies.\n\n# Import packages, most for parsing the tweets.js file\n\nimport numpy as np\nimport pandas as pd\nimport duckdb\nimport json\nimport time\nimport datetime\nimport pytz\nfrom dateutil.tz import tzlocal\n\n\n\nParsing My Tweets Data\nWe’ll create a function to can load the tweets.js in as a pandas data frame. While the Javascript file was a little tricky at first I realized it was JSON with some extra text at the front.   Opening the file, removing that text, and then normalizing the JSON let’s us read in the tweets data as a Pandas Data Frame without too much fuss.\n\n# Adapting a parsing function from here but extended it to go into a DF \n# https://github.com/dangoldin/twitter-archive-analysis/blob/master/analyze.py\n\ndef load_tweets_from_js(js_file):\n    with open(js_file, \"r\") as f:\n        data = f.read()\n        data = data.replace(\"window.YTD.tweets.part0 = \", \"\")\n        tweets = json.loads(data)\n        for tweet in tweets:\n            ts = datetime.datetime.strptime(\n                tweet[\"tweet\"][\"created_at\"], \"%a %b %d %H:%M:%S +0000 %Y\"\n            )\n            ts = ts.replace(tzinfo=pytz.utc)\n            ts = ts.astimezone(tzlocal())\n            tweet[\"timestamp\"] = ts\n        print(\"Loaded %d tweets\" % len(tweets))\n        tweets_df = pd.json_normalize(tweets)\n        return tweets_df\n\n\n\nSome Initial Tidying with Pandas\nOne great aspect of using local data is we don’t have to abandon other tools we know and love to exclusively use SQL. For example, we can use Pythonic methods to rename all our columns in a way that won’t collide with the SQL interpreter5 in a single line of code.\n\n# Use the function to create a Pandas DataFrame\n\ntweets = load_tweets_from_js(\"tweets.js\")\n\n# Replace periods with underscores so they don't confuse SQL later\n\ntweets.columns = tweets.columns.str.replace(\".\", \"_\",regex = False)\n\n# Convert multiple columns to numeric at once\n# Only doing with two columns here but could work with many more\n\nsecret_numeric = [\"tweet_favorite_count\",\"tweet_retweet_count\"]\n\ntweets[secret_numeric] = tweets[secret_numeric].apply(pd.to_numeric)\n\n# Confirm the conversion worked (Commented out because it did!)\n# tweets.dtypes\n\nLoaded 5244 tweets\n\n\n\n\nAn Example DuckDB Query on a Pandas Data Frame\nNow we can use DuckDB as a querying engine directly on this pandas data frame!   Here’s a simple example to start, where we use DuckDB to (gulp) look at how many likes my tweets have gotten on average:\n\nprint(duckdb.query(\"SELECT AVG(tweet_favorite_count) as avg_favorite_count FROM tweets\").to_df())\n\n   avg_favorite_count\n0            5.127002\n\n\n\n\nComparing the Speed of DuckDB and Pandas on My Twitter Archive\nOk, so how long does this take on my non-enormous Twitter archive? Let’s create a timing function first.\n\ndef time_duckdb(full_query):\n  start = time.time()\n  duckb_query = duckdb.query(full_query).to_df()\n  end = time.time()\n  print(round(end - start, 4))\n\n\ntime_duckdb(\"SELECT AVG(tweet_favorite_count) as avg_favorite_count FROM tweets\")\n\n0.0507\n\n\nPretty quick! How does this simple DuckDB query compare to an equivalent Pandas operation?\n\nstart_pd_simple = time.time()\ntest_pandas_avg = tweets.agg(avg_favorite_count = (\"tweet_favorite_count\", \"mean\"))\nend_pd_simple = time.time()\nprint(round(end_pd_simple - start_pd_simple, 4))\n\n0.0039\n\n\nOn simple queries on non-enormous data6 Pandas seems to still be much faster than DuckDB. That lead would diminish and eventually disappear on larger data. \n\n\nSometime We Might Prefer to Write SQL\nAnd even if Pandas is faster on data of this size sometimes we might prefer to use DuckDB anyway.   For example, the syntax for doing a filtered “group by” using SQL is more intuitive to me than the equivalent Pandas syntax. Either works, and as we can see here Pandas is still faster on data at this size!\n\ntime_duckdb(\"SELECT AVG(tweet_favorite_count) as avg_favorite_count FROM tweets WHERE tweet_retweet_count > 10 GROUP BY tweet_truncated\")\n\n0.0497\n\n\n\nstart = time.time()\nfiltered_pandas = tweets[tweets[\"tweet_retweet_count\"] >= 1]\ngrouped_avg_pandas = filtered_pandas.groupby('tweet_truncated', as_index=False).agg(avg_favorite_count = (\"tweet_favorite_count\", \"mean\"))\nend = time.time()\nprint(round(end - start, 4))\n\n0.0057\n\n\nAnd since in this case the speed differential is negligible7 having another option for data wrangling can be handy.   DuckDB also has the virtue of being far more scalable than Pandas. That scalability extends to much larger data, much more complex data wrangling, and both of those complexities combined.\n\n\nConclusion\nI had a good time exploring a more compact use-case for DuckDB. I was a bit surprised how much faster the Pandas queries ran vs. DuckDB at “small-ish data” size. I figured the two appraoaches would be closer in speed, though this may be a quirk of running Python through Quarto.   I’m hoping this is just a warm-up act for my journey with DuckDB! I’m especially excited about DuckDB as a key catalyst for running the Modern Data Stack on a laptop, and if you’re also intrigued I recommend checking out this proof-of-concept by Jacob Matson.   If you have any questions or comments I’d love to hear from you! For at least a while I’m on Twitter, and other contact info is on my website.\n\n\n\n\n\nFootnotes\n\n\nData Mastodon? Data 138-Different-Discord-Servers?↩︎\nNo external dependencies like SQLite with a lot more features, thorough testing with CI, open source↩︎\nAs of me writing this I don’t believe you can work directly on data frames or tibble in R, though you can interface with DuckDB using the dbplyr package https://duckdb.org/docs/api/r↩︎\nOr maybe not, as we’ll see soon!↩︎\nReplacing all the “.” in variable names with “_” so the SQL interpreter doesn’t think we’re referencing a variable within another table↩︎\nIn this case ~10 MB↩︎\nBoth styles of queries are more than fast enough!↩︎"
  },
  {
    "objectID": "posts/2022_10_26_participatory_case_studies/index.html",
    "href": "posts/2022_10_26_participatory_case_studies/index.html",
    "title": "How Do I Get People to Pay Attention to My Data Deliverables?",
    "section": "",
    "text": "Everyone wants their work to be recognized. Recognition can come in a lot of different forms, and none1 of them are possible if people don’t pay attention to your work.   I’ve come up with a system that can effectively captured my stakeholders’ attention. There are important caveats,2 and I thought it might be useful to share my approach. Please feel free to try, remix, and let me know how it goes!"
  },
  {
    "objectID": "posts/2022_10_26_participatory_case_studies/index.html#general-structure",
    "href": "posts/2022_10_26_participatory_case_studies/index.html#general-structure",
    "title": "How Do I Get People to Pay Attention to My Data Deliverables?",
    "section": "General Structure",
    "text": "General Structure\nRather than have people feel like they’re passively consuming my data deliverable, I want them to feel involved in the process. My general structure goes like this:   1. Have a hook that draws people in  2. Give them a quick and easy way to think about their expectations  3. Follow all the wonderful advice about tailoring your deliverable to the audience"
  },
  {
    "objectID": "posts/2022_10_26_participatory_case_studies/index.html#a-case-study",
    "href": "posts/2022_10_26_participatory_case_studies/index.html#a-case-study",
    "title": "How Do I Get People to Pay Attention to My Data Deliverables?",
    "section": "A Case Study",
    "text": "A Case Study\nFor example, I was presenting a case study on the results of an experiment at my job. Previously only the folks who were required to read this kind of report had read them, and only grudgingly. This time when I shared the result, I:   1. Didn’t put the results directly in Slack, and instead asked whether people thought they could guess how well the experiment had worked.  2. I then linked to a Typeform survey where people answered two quick questions - one about how they thought the experiment went and another about how confident they were in their guess  3. The end of that survey automatically redirected to a stakeholder report designed to be accessible to people with little time and context5   After this simple change we went from 2-3 people skimming the case study results to nearly 50% of our small startup discussing the results in Slack. Using the survey also helped me track how many people viewed the report and what their expectations were about the experiment before knowing the results."
  },
  {
    "objectID": "posts/2022_10_20_ultra_parameterized_reports/index.html",
    "href": "posts/2022_10_20_ultra_parameterized_reports/index.html",
    "title": "Parameterized Reports in Disguise",
    "section": "",
    "text": "At one of my jobs we ran ~monthly pilot studies. Strong performance in each pilot was key to securing business long-term. Naturally, knowing how well we were doing in the pilot as quickly as possible was top priority. The pilot report could help identify potential pain points, let everyone breathe a sigh of relief, or1 a bit of both.   One problem: pilot reports before I arrived were redone by hand for every pilot. While some of the code from previous pilots could be copy/pasted that introduced a whole new set of issues. This ad-hoc approach meant each pilot report took almost a full work week to build.2   After I introduced ultra-parameterized reports, we were able to provide pilot reports the moment the data became available.3 Other decision-makers could react faster, and the company’s capacity to capitalize on the report grew a ton."
  },
  {
    "objectID": "posts/2022_10_20_ultra_parameterized_reports/index.html#example-script-without-parameters",
    "href": "posts/2022_10_20_ultra_parameterized_reports/index.html#example-script-without-parameters",
    "title": "Parameterized Reports in Disguise",
    "section": "Example Script Without Parameters",
    "text": "Example Script Without Parameters\nHere’s a script that gives you an incredible amount of information on elevators in New York but isn’t parameterized yet.\n---\ntitle: \"Cool graphs about elevators\"\nauthor: Mike Mahoney\nsubtitle: \"Last generated on:\"\ndate: today\nformat:\n  html:\n    echo: false\n---\n\n```{r}\n#| message: false\nlibrary(elevators)\nlibrary(ggplot2)\ntheme_set(theme_minimal())\n```\n\n## Speed over time\n\n```{r}\n#| message: false\n#| warning: false\nelevators |>\n  ggplot(aes(approval_date, speed_fpm)) +\n  geom_point(alpha = 0.05) +\n  geom_smooth() +\n  scale_y_log10()\n```\n\n## Speed versus capacity\n\n```{r}\n#| message: false\n#| warning: false\nelevators |>\n  ggplot(aes(capacity_lbs, speed_fpm)) +\n  geom_point(alpha = 0.05) +\n  geom_smooth() +\n  scale_y_log10()\n```\n\n## Where in the world did all my elevators go\n\n```{r}\nelevators |>\n  ggplot(aes(longitude, latitude)) + \n  geom_point(alpha = 0.05) +\n  coord_sf()\n```"
  },
  {
    "objectID": "posts/2022_10_20_ultra_parameterized_reports/index.html#example-script-with-parameters",
    "href": "posts/2022_10_20_ultra_parameterized_reports/index.html#example-script-with-parameters",
    "title": "Parameterized Reports in Disguise",
    "section": "Example Script With Parameters",
    "text": "Example Script With Parameters\nAnd here’s a parameterized script that gives you an incredible amount of information on elevators specifically in Manhattan.   The key difference here isn’t so much that we can get info on Manhattan, it’s that we can swap out “Brooklyn” for “Manhattan” in about 0.2 seconds to re-run the report. A lot less manual work than copy-pasting Brooklyn for Manhattan everywhere and hoping we didn’t miss anything!  \n---\ntitle: \"Cool graphs about elevators\"\nauthor: Mike Mahoney\nsubtitle: \"Last generated on: 2022-10-25\"\ndate: today\nformat: \n  html: \n    echo: false\nparams: \n  borough: \"Manhattan\"\n---\n\n```{r}\n#| message: false\nlibrary(elevators)\n\nif (!is.na(params$borough) && params$borough != \"NA\") {\n  elevators <- elevators[elevators$borough == params$borough, ]\n}\nif (nrow(elevators) == 0) {\n  stop(\"No elevators were selected. Did you misspell `borough`?\")\n}\n\nlibrary(ggplot2)\ntheme_set(theme_minimal())\n```\n\n## Speed over time\n\n```{r}\n#| message: false\n#| warning: false\nelevators |> \n  ggplot(aes(approval_date, speed_fpm)) + \n  geom_point(alpha = 0.05) + \n  geom_smooth() + \n  scale_y_log10()\n```\n\n## Speed versus capacity\n\n```{r}\n#| message: false\n#| warning: false\nelevators |> \n  ggplot(aes(capacity_lbs, speed_fpm)) + \n  geom_point(alpha = 0.05) + \n  geom_smooth() + \n  scale_y_log10()\n```\n\n## Where in the world did all my elevators go\n\n```{r}\nelevators |> \n  ggplot(aes(longitude, latitude)) + \n  geom_point(alpha = 0.05) + \n  coord_sf()\n```"
  },
  {
    "objectID": "posts/2022_10_20_ultra_parameterized_reports/index.html#we-were-promised-disguises",
    "href": "posts/2022_10_20_ultra_parameterized_reports/index.html#we-were-promised-disguises",
    "title": "Parameterized Reports in Disguise",
    "section": "We Were Promised Disguises",
    "text": "We Were Promised Disguises\nThis is where mustache starts providing the “ultra” in “ultra-parameterized.” Using the whisker package implementation in R, we can create a version of the script that will allow us to programmatically specify the borough during report creation.   The only difference between this version and the parameterized report is replacing “Manhattan” with “{{ borough }}”\n---\ntitle: \"Cool graphs about elevators\"\nauthor: Mike Mahoney\nsubtitle: \"Last generated on: 2022-10-25\"\ndate: today\nformat: \n  html: \n    echo: false\nparams: \n  borough: {{ borough }}\n---\n\n```{r}\n#| message: false\n#| results: false\nlibrary(elevators)\n\nif (!is.na(params$borough) && params$borough != \"NA\") {\n  elevators <- elevators[elevators$borough == params$borough, ]\n}\nif (nrow(elevators) == 0) {\n  stop(\"No elevators were selected. Did you misspell `borough`?\")\n}\n\nlibrary(ggplot2)\ntheme_set(theme_minimal())\n```\n\n## Speed over time\n\n```{r}\n#| message: false\n#| warning: false\nelevators |> \n  ggplot(aes(approval_date, speed_fpm)) + \n  geom_point(alpha = 0.05) + \n  geom_smooth() + \n  scale_y_log10()\n```\n\n## Speed versus capacity\n\n```{r}\n#| message: false\n#| warning: false\nelevators |> \n  ggplot(aes(capacity_lbs, speed_fpm)) + \n  geom_point(alpha = 0.05) + \n  geom_smooth() + \n  scale_y_log10()\n```\n\n## Where in the world did all my elevators go\n\n```{r}\nelevators |> \n  ggplot(aes(longitude, latitude)) + \n  geom_point(alpha = 0.05) + \n  coord_sf()\n```"
  },
  {
    "objectID": "posts/2022_10_20_ultra_parameterized_reports/index.html#creating-a-function-to-run-render-many-reports",
    "href": "posts/2022_10_20_ultra_parameterized_reports/index.html#creating-a-function-to-run-render-many-reports",
    "title": "Parameterized Reports in Disguise",
    "section": "Creating a Function to Run + Render Many Reports",
    "text": "Creating a Function to Run + Render Many Reports\nWe now need another file that will replace “{{ borough }}” with the appropriate boroughs and render each report.\n---\ntitle: \"Create All Borough Reports\"\nauthor: \"Michael Mullarkey\"\n---\n\n# Load Packages\n\n```{r}\n\nlibrary(whisker)    # For replacing {{ }} text\nlibrary(tidyverse)  # For function creation + data wrangling\nlibrary(glue)       # For programmatic file naming\nlibrary(lubridate)  # For today()\nlibrary(here)       # For better file paths\nlibrary(quarto)     # For rendering\nlibrary(elevators)  # For elevators data\n\n```\n\n# Use Whisker to Modify Template .qmd File with Desired Values\n\n```{r}\n\nuse_borough_template <- function(borough, file_name) {\n  \n  raw_qmd <- readLines(file_name) # Reading in full .qmd file\n  \n  filled_qmd <- whisker.render(raw_qmd) # Replace {{}} with borough value \n  \n  writeLines(\n    text = filled_qmd,\n    con = glue(\"{borough}_{today()}.qmd\") # Programmatic naming so we don't\n    # just overwrite the same file again and again when we iterate\n  )\n    \n}\n\n```\n\n# Render .qmd Files Using Programmatic Names\n\n```{r}\n\nrender_borough_template <- function(borough, file_name) {\n  \n  quarto_render(\n    input = glue(\"{borough}_{today()}.qmd\")\n  )\n  \n}\n\n```\n\n# Put Both Functions Together So We Only Have to Make One Function Call\n\n```{r}\n\ncreate_borough_report <- function(borough, file_name) {\n  \n  use_borough_template(borough = borough, file_name = file_name)\n  \n  render_borough_template(borough = borough, file_name = file_name)\n  \n}\n\n```\n\n# Testing the report creation once before going on to programmatic\n\n```{r}\n\n# Testing the report creation once before going on to programmatic\n\n# create_borough_report(borough = \"Manhattan\", file_name = \"borough_template.qmd\")\n\n```\n\n# Creating a dataframe of information to map over\n\n```{r}\n\n# Create data frame to map over for borough reports\n\nall_boroughs <- elevators::elevators %>% \n  distinct(borough) %>% \n  deframe()\n\nfile_name_vec <- rep(\"borough_template.qmd\", length(all_boroughs))\n\nboroughs_report_df <- tibble(all_boroughs, file_name_vec)\n\n```\n\n# Map over all borough reports\n\n```{r}\n\n# This also could be walk because we're really just looking for side effects!\n\n# Not necessary to do pmap for this example but it's more extensible to if you\n# need to use more than 2 paramters (otherwise can use map or map2)\n\npmap(\n  boroughs_report_df,\n  ~create_borough_report(\n    borough = ..1,\n    file_name = ..2\n  )\n)\n\n```\nOnce you have a file like this that can programmatically replace your parameters and render reports you’re good to go!   You can check out the programmatically generated reports for Manhattan the Bronx, Brooklyn, Queens, and Staten Island.9   If stakeholders have a small tweak they want to one report but not others you can make that edit just in one .qmd file and then re-render it.10"
  },
  {
    "objectID": "posts/2024_04_24_mlcheck_intro/index.html",
    "href": "posts/2024_04_24_mlcheck_intro/index.html",
    "title": "Introducing mlcheck",
    "section": "",
    "text": "What is mlcheck for?\nI primarily see this tool as a way to check myself. The idea for mlcheck came to me after I realized I’d forgotten to set a random_state to make my train/test split reproducible!\nAnd I was still curious how often these ML best practices get used in the wild.\nSo, I created a shell script to download a couple hundred+3 .py files from Github that contain “sklearn”\nI used this pattern as a rough proxy for people implementing scikit-learn style Python code.\nAfter downloading all those files, I ran mlcheck on the entire folder with one command line call.\nHere’s what mlcheck’s output looks like on the command line for a single file:\n\n\n\nmlcheck output showing mlcheck with ascii art and displaying which best practice checks were passed and failed along with the percentage of checks passed\n\n\nWhat were the results?\nFirst, this tool absolutely did not have to be in Rust4, and wow was this implementation fast.\nAccording to a SQL query on the database created by running the checks, mlcheck performed all the best practice checks across hundreds of files in 0.94 seconds.\nAnd best-practice usage was by no means universal. Another SQL query showed that while at least one file passed 100% of the best-practice checks, the average for checks passed was just 33.48%.\nThis average is even more remarkable when you consider the minimum percentage of checks passed was 20%. After all, one of the checks is whether sklearn is detected or not, and unless I messed up the original shell script passing that check was guaranteed.\nI don’t want to pretend this group of files is a representative sample, and people could use these code files in situations where best practices are unnecessary.\nAnd I know I’ve skipped past best practices because “I know what I’m doing!” I’m not alone in that boat.\nIf you’re interested in checking out the demo, the entire repo is here\n\n\nWhat if I want to use mlcheck?\nIf you’re interested in using mlcheck check out its repo here for installation and usage instructions. This tool is still pretty new so there’s definitely a chance of breaking changes. However, I know this tool has already saved me at least once, and I want others to have that opportunity as well.\n\n\n\n\n\nFootnotes\n\n\nJupyter notebooks, which btw have the wildest file extension↩︎\ntidymodels style code in .R, .Rmd, and .qmd files is on the roadmap↩︎\nI ran into Github rate limits going much higher than that at once, and even still didn’t always get a consistent number of downloads using a lower number.↩︎\nI wanted to learn more Rust and used this project as an excuse!↩︎"
  },
  {
    "objectID": "posts/2022_11_13_birdwatch_data/index.html",
    "href": "posts/2022_11_13_birdwatch_data/index.html",
    "title": "Assessing the Scalability of Birdwatch",
    "section": "",
    "text": "A recent Washington Post article dove deep on Twitter’s crowd-sourced fact-checking program Birdwatch. Twitter’s owner touted the volunteer-driven initiative around the same time 15% of Trust and Safety staff were laid off. A week later a large number of content moderation contractors1 were fired without notice and the head of Trust and Safety resigned.  Data related to trust and safety are rarely open for audit, but Birdwatch2 has provided open source data, code, and documentation since it started as a small pilot program in January 2021. I decided to do an initial assessment of the open data with an eye toward Birdwatch’s scalability as a content moderation tool."
  },
  {
    "objectID": "posts/2022_11_13_birdwatch_data/index.html#a-quick-primer-on-how-birdwatch-works",
    "href": "posts/2022_11_13_birdwatch_data/index.html#a-quick-primer-on-how-birdwatch-works",
    "title": "Assessing the Scalability of Birdwatch",
    "section": "A Quick Primer on How Birdwatch Works",
    "text": "A Quick Primer on How Birdwatch Works\nAny Twitter user can join Birdwatch with the ultimate goal of adding notes to tweets. Those notes can fact-check, provide additional context, and in theory deter disinformation.   There are checks and balances on the Birdwatch system geared toward stopping bad-faith actors. While anyone can join Birdwatch you cannot write your own initial notes on tweets when you join. First, you must consistently submit ratings of others’ initial notes that agree with the other Birdwatch members’ general consensus.   Those ratings from Birdwatch members also serve as a powerful bottleneck for which initial notes ultimately appear on tweets. The ranking for whether a note is “helpful” enough to apply to a tweet is more complex than a majority vote among Birdwatch members.   Instead, initial notes that receive a few positive ratings from people who normally disagree on their ratings are more likely to be rated as helpful than initial notes that receive many positive ratings from people who normally agree.  This system is known as bridge-based ranking and algorithmically prioritizes this form of consensus over potential alternatives The Washington Post article notes this approach is unlikely to scale, especially in “an era when left and right often lack a shared set of facts.”   To see how well this approach does or does not scale right now, let’s dive into the data."
  },
  {
    "objectID": "posts/2022_11_13_birdwatch_data/index.html#how-many-tweets-have-initial-notes",
    "href": "posts/2022_11_13_birdwatch_data/index.html#how-many-tweets-have-initial-notes",
    "title": "Assessing the Scalability of Birdwatch",
    "section": "How Many Tweets Have Initial Notes?",
    "text": "How Many Tweets Have Initial Notes?\n\n\nCode\n# Grouping by tweetId and counting number of notes per tweet\n\ntweets_initial_notes = initial_notes.groupby(\"tweetId\").count()\n\n# Use f-strings to get key info\n\nprint(f\"Birdwatchers have put initial notes on {len(tweets_initial_notes)} tweets since January of 2021.\")\n\n\nBirdwatchers have put initial notes on 28723 tweets since January of 2021."
  },
  {
    "objectID": "posts/2022_11_13_birdwatch_data/index.html#how-does-this-compare-to-the-total-volume-of-tweets",
    "href": "posts/2022_11_13_birdwatch_data/index.html#how-does-this-compare-to-the-total-volume-of-tweets",
    "title": "Assessing the Scalability of Birdwatch",
    "section": "How Does This Compare to the Total Volume of Tweets?",
    "text": "How Does This Compare to the Total Volume of Tweets?\nFor context, there are approximately 500,000,000 tweets sent per day.   Even if we assume that only the top 0.1% of tweets require the scrutiny of Birdwatch that would mean 500 tweets should be considered for notes per day.  We can be extra generous and say fewer tweets than that might require notes, but we’d still expect around 500 notes per day. How many days in the Birdwatch data meet that criteria?\n\n\nCode\n# Converting to date instead of milliseconds since epoch\n\ninitial_notes[\"dateCreated\"] = pd.to_datetime(initial_notes[\"createdAtMillis\"], unit = \"ms\").dt.date\n\n# Counting the number of notes per day\n\ntweet_initial_dates = initial_notes.groupby([\"dateCreated\"]).count()\n\n# Finding the earliest date\n\nmin_tweet_date = tweet_initial_dates.index.min()\n\n# Finding how many dates where over 500 notes or more were created\n\ndays_500_per = tweet_initial_dates[tweet_initial_dates.tweetId >= 500]\n\n# Getting value of only date where >500 notes were created\n\nonly_date_over = days_500_per.index.values\n\nprint(f\"In all Birdwatch data going back to {min_tweet_date}, there was {len(days_500_per)} day where at least 500 notes were written - {only_date_over[0]}\")\n\n\nIn all Birdwatch data going back to 2021-01-23, there was 1 day where at least 500 notes were written - 2021-01-28\n\n\nEven with relaxed criteria, there was only 1 day at the very beginning of Birdwatch where the community reviewed approximately 0.1% of all tweets in a day.   This relatively low review volume is understandable given Birdwatch is an almost all-volunteer effort. However, this precedent of not operating at scale becomes concerning if Birdwatch is expected to play a large role in preventing disinformation on the platform."
  },
  {
    "objectID": "posts/2022_11_13_birdwatch_data/index.html#how-many-initial-notes-need-more-ratings-to-determine-their-helpfulness",
    "href": "posts/2022_11_13_birdwatch_data/index.html#how-many-initial-notes-need-more-ratings-to-determine-their-helpfulness",
    "title": "Assessing the Scalability of Birdwatch",
    "section": "How Many Initial Notes Need More Ratings to Determine Their Helpfulness?",
    "text": "How Many Initial Notes Need More Ratings to Determine Their Helpfulness?\n\n\nCode\n# Getting status for which notes were rated as helpful or not\n\nnote_status = initial_history[[\"noteId\",\"currentStatus\"]]\n\n# Seeing what percentage of notes with evaluations need more evaluation\n\nstatus_counts = note_status.currentStatus.value_counts()\n\npd.DataFrame(status_counts)\\\n.assign(percent = lambda x: (x[\"currentStatus\"] / x[\"currentStatus\"].sum()) * 100)\\\n.round(2)\n\n\n\n\n\n\n  \n    \n      \n      currentStatus\n      percent\n    \n  \n  \n    \n      NEEDS_MORE_RATINGS\n      14517\n      86.90\n    \n    \n      CURRENTLY_RATED_HELPFUL\n      1506\n      9.01\n    \n    \n      CURRENTLY_RATED_NOT_HELPFUL\n      683\n      4.09\n    \n  \n\n\n\n\nAnother indication that an all-volunteer effort isn’t enough to scale this form of content moderation - nearly 87% of initial notes need more ratings to determine whether they could be helpful or not.   All initial notes start out as “Needs More Ratings” until they’ve received at least 5 ratings, and it appears a vast majority of notes never meet that threshold.   There could be multiple reaons for this, ranging from charitable4 to less so.5 There could be reasons internal to the Birdwatch community I’m unaware of that drive this pattern.   And no matter what, the current Birdwatch system is failing to identify whether a vast majority initial notes are helpful. This is true even though the volume of initial notes is infentisimal compared to the total volume of tweets. If more initial notes were written to better keep up with overall tweet volume, there’s a chance this lack of ratings problem would be exacerbated."
  },
  {
    "objectID": "posts/2022_11_13_birdwatch_data/index.html#example-the-tweet-with-the-most-initial-notes-had-no-notes-with-enough-ratings",
    "href": "posts/2022_11_13_birdwatch_data/index.html#example-the-tweet-with-the-most-initial-notes-had-no-notes-with-enough-ratings",
    "title": "Assessing the Scalability of Birdwatch",
    "section": "Example: The Tweet With the Most Initial Notes Had No Notes with Enough Ratings",
    "text": "Example: The Tweet With the Most Initial Notes Had No Notes with Enough Ratings\n\n\nCode\nprint(f\"The tweet with the most initial notes had {tweets_initial_notes.noteId.max()} notes.\")\n\n# tweets_initial_notes[tweets_initial_notes.noteId == 58]\n# Can use this website to get tweets from tweetId without using the API https://www.bram.us/2017/11/22/accessing-a-tweet-using-only-its-id-and-without-the-twitter-api/\n\n\nThe tweet with the most initial notes had 58 notes.\n\n\nThe tweet with the most initial notes was by Rep. Alexandria Ocasio-Cortez in response to Senator Ted Cruz. The tweet touched on the trading platform Robinhood’s decision to prevent retail investors from trading certain stocks and the January 6th insurrection.  This tweet ultimately did not have a note attached to it.   Tweets could not have a note attached to them for 2 reasons:  1. There is no note rated as helpful  2. There is at least one note rated as helpful but the Tweet is not marked as “potentially misleading”  In this case no initial note was rated as helpful, and to boot none of the initial notes had enough ratings to even be considered.\n\n\nCode\n# Getting all noteIds in reference to the AOC tweet into a list\n\naoc_note_ids = initial_notes[initial_notes[\"tweetId\"] == 1354848253729234944].noteId.to_list()\n\n# Filtering the note history based on this list and counting values\n\ninitial_history[initial_history[\"noteId\"].isin(aoc_note_ids)].currentStatus.value_counts()\n\n\nNEEDS_MORE_RATINGS    54\nName: currentStatus, dtype: int64\n\n\nEven if you believe this tweet should not have received a note,6 it’s troubling that its status remained up in the air rather than seeing a definitive “not helpful” label applied to all initial notes."
  },
  {
    "objectID": "posts/2022_11_13_birdwatch_data/index.html#would-more-birdwatch-members-solve-all-these-problems",
    "href": "posts/2022_11_13_birdwatch_data/index.html#would-more-birdwatch-members-solve-all-these-problems",
    "title": "Assessing the Scalability of Birdwatch",
    "section": "Would More Birdwatch Members Solve All These Problems?",
    "text": "Would More Birdwatch Members Solve All These Problems?\nThe two previous scalability issues could, at least in principle, be solved by having a lot more people joining Birdwatch. More initial notes could be written, more initial notes could receive ratings, and the system could achieve at least some scalability.  However, there are reasons to believe that using its current standards more members could actually make Birdwatch less scalable.   Think back to the example of the tweet with the most initial notes ever. Lots of people wrote initial notes, but nowhere near enough people rated all those initial notes.   It’s possible Birdwatch has better procedures in place now, but it seems like more Birdwatch members could exacerbate this coordination problem. Too many people writing initial notes, and - after the initial probationary period - not enough people rating initial notes."
  },
  {
    "objectID": "posts/nba_2020_2021_mirage_metrics/index.html",
    "href": "posts/nba_2020_2021_mirage_metrics/index.html",
    "title": "NBA Mirage Metrics:Looking for the Unsustainable",
    "section": "",
    "text": "How good is your favorite NBA team really? This is a surprisingly difficult question to answer!  I can already hear some people yelling “Scoreboard!” and pointing at readily available wins and losses for each team.   And even the most die-hard fans will admit their team sometimes gets lucky.1 A banked 3-pointer, an untimely injury to the opposing team’s star, and so much more can make the wins and losses less reliable than they first appear.   Folks have looked at a bunch of metrics to better quantify team quality outside of luck. Average point differential per 100 possessions, the 4 factors, and many more can give us a clearer guide to how good teams are. But what if we wanted to specifically quantify how lucky they’ve been?   A precise quantification of that isn’t going to happen, at least not at scale.2 But there are certain, easily measured metrics that seem to be more luck than skill-based.   Drawing on Seth Partnow’s The Midrange Theory and a myriad of Caitlin Cooper film deep-dives we’ll assume:  - Defenses don’t affect how well opponents shoot from 3 + Long 23  - Offenses built on high-volume, very high accuracy long 2s are less sustainable than other kinds of offense4  - Offenses built on high-volume, unassisted high accuracy 3s are less sustainable than other kinds of offense5   Then, we’ll explore which 2021-2022 NBA teams may have appeared better on offense and defense than they actually were."
  },
  {
    "objectID": "posts/nba_2020_2021_mirage_metrics/index.html#defenstive-mirage-metrics",
    "href": "posts/nba_2020_2021_mirage_metrics/index.html#defenstive-mirage-metrics",
    "title": "NBA Mirage Metrics:Looking for the Unsustainable",
    "section": "Defenstive Mirage Metrics",
    "text": "Defenstive Mirage Metrics\n\n\nCode\nopp_shot_league %>% \n  left_join(logos, by = \"team\") %>% \n  ggplot(aes(three_vs_league, long2_vs_league)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_image(aes(image = image_url)) +\n  # geom_text(data = plot_labels, aes(x, y, label = lab_text), size = 2) +\n  geom_abline(slope = -2.5, intercept = seq(from = -8, to = 8, by = 4)/100, alpha = .2) +\n  scale_x_reverse(label = percent) +\n  scale_y_reverse(label = percent) +\n  theme_minimal() +\n  theme(text = element_text(family = \"graduate\")) +\n  labs(x = \"Opponent 3P% vs. League Average\",\n       y = \"Opponent Long 2% vs. League Average\",\n       title = \"Defensive Mirage Metrics for Full 2021-2022 NBA Season\",\n       caption = \"Further Up & Right = More of a Mirage\")\n\n\n\n\n\nThese plots take inspiration from the expected points added plots popularized via the nflfastr package by Ben Baldwin.   These plots allow us to see defensive mirage tiers rather than hard and fast rankings. I like that this plot communicates the inherent uncertainty in these metrics in an interesting way.   From a basketball perspective, we can see you need to be lucky and good to be a top defense in the NBA. I don’t think anyone would argue that the Golden State Warriors had a bad defense last year, and their already excellent defense benefitted from a lot of poor opponent shooting luck.   A couple of teams with a larger gap between “the eye test” and their defensive ratings last season also show up among the luckiest teams on defense. Put it this way: I’m not betting on either the Mavs or the Knicks having a top-tier defense again in 2022-2023."
  },
  {
    "objectID": "posts/nba_2020_2021_mirage_metrics/index.html#offensive-mirage-metrics",
    "href": "posts/nba_2020_2021_mirage_metrics/index.html#offensive-mirage-metrics",
    "title": "NBA Mirage Metrics:Looking for the Unsustainable",
    "section": "Offensive Mirage Metrics",
    "text": "Offensive Mirage Metrics\n\n\nCode\nteam_shot_league %>% \n  left_join(logos, by = \"team\") %>% \n  ggplot(aes(three_mirage, long2_mirage)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_image(aes(image = image_url)) +\n  # geom_text(data = plot_labels, aes(x, y, label = lab_text), size = 2) +\n  geom_abline(slope = -2.5, intercept = seq(from = -7.5, to = 4.5, by = 3), alpha = .2) +\n  theme_minimal() +\n  theme(text = element_text(family = \"graduate\")) +\n  theme(axis.title = element_text(size = 9)) +\n  labs(x = \"Unassisted 3 Rate & 3P% vs. League Average - Z-Scored\",\n       y = \"Long 2 Volume & Long 2P% vs. League Average - Z-Scored\",\n       title = \"Offensive Mirage Metrics for Full 2021-2022 NBA Season\",\n       caption = \"Further Up & Right = More of a Mirage\")\n\n\n\n\n\nThe offensive mirage statistics continue the “need to be lucky and good” story. The Atlanta Hawks had the 2nd best offensive rating in the NBA during 2021-2022, and they had an absurdly high rate of accurate, unassisted 3 pointers. You can point to all the excellent shooting Atlanta had, and also recognize that some regression to the mean is likely in 2022-2023.   Same for Brooklyn and Chicago - two teams with absurdly elite midrange shooters that might still see a bit of regression in that category this year. Case in point, the Suns are also full of elite midrange shooters and are almost a full standard deviation below Chicago on the Long 2 mirage metric."
  },
  {
    "objectID": "posts/nba_2020_2021_mirage_metrics/index.html#additional-cleaning",
    "href": "posts/nba_2020_2021_mirage_metrics/index.html#additional-cleaning",
    "title": "NBA Mirage Metrics:Looking for the Unsustainable",
    "section": "Additional Cleaning",
    "text": "Additional Cleaning\nAs much fun as these plots are, they don’t weight 3 point luck more heavily than 2 point luck. I’ve also wanted to teach myself reactable and reactablefmtr for a bit, and this project gave me a great excuse! Shout out to Tanya Shapiro for introducing me to this package via Twitter.\n\n\nCode\ncleaned_table <- team_shot_league %>% \n  left_join(opp_shot_league, by = \"team\") %>% \n  left_join(logos, by = \"team\") %>% \n  mutate(across(\n    c(weighted_team_shot:long2_mirage),\n    ~round(.x, 1)\n  ),\n  across(\n    c(weighted_team_shot:long2_mirage),\n    ~case_when(\n    .x < 0 ~ \"#127852\",\n    .x > 0 ~  '#C40233',\n    TRUE ~ '#A5A0A1'\n    ),\n    .names = \"colors_{col}\"\n  ),\n  across(\n    c(weighted_opp_shot:long2_vs_league),\n    ~case_when(\n    .x < 0 ~ '#C40233',\n    .x > 0 ~  \"#127852\",\n    TRUE ~ '#A5A0A1'\n    ),\n    .names = \"colors_{col}\"\n  )\n  ) \n\n\nThere was a bit more cleaning necessary to prepare the data for these tables, and I went through several iterations before settling on the current versions.\n\n\nCode\ninitial_table <- cleaned_table %>% \n  rename(Team = team, `Total Offensive Mirage` = weighted_team_shot, \n         `Offensive Mirage 3` = three_mirage,\n         `Offensive Mirage Long 2` = long2_mirage,\n         `Opponent Long-Range EFG% vs. League Average` = weighted_opp_shot,\n         `Opponent 3P% vs. League Average` = three_vs_league,\n         `Opponent Long 2% vs. League Average` = long2_vs_league) %>% \n  relocate(image_url, Team, everything())\n\n\nHuge shout-out to the extensive vignettes and documentation behind the reactablefmtr package. Going from 0 to these tables was a much smoother, more interesting process than I anticipated!\n\n\nCode\noff_metrics_table <- initial_table %>% \n  select(image_url, Team, contains(\"Offensive\"),c(colors_weighted_team_shot:colors_long2_mirage))\n\ndef_metrics_table <- initial_table %>% \n  select(image_url, Team, contains(\"Opponent\"),c(colors_weighted_opp_shot:colors_long2_vs_league))"
  },
  {
    "objectID": "posts/nba_2020_2021_mirage_metrics/index.html#defensive-mirage-metrics",
    "href": "posts/nba_2020_2021_mirage_metrics/index.html#defensive-mirage-metrics",
    "title": "NBA Mirage Metrics:Looking for the Unsustainable",
    "section": "Defensive Mirage Metrics",
    "text": "Defensive Mirage Metrics\n\n\nCode\ndef_metrics_table %>% \nreactable(\n          pagination = FALSE,\n          searchable = TRUE,\n          defaultSorted = \"Opponent Long-Range EFG% vs. League Average\",\n          style = list(fontFamily = \"graduate\"),\n          theme = espn(centered = TRUE, header_font_size = 10, \n                       cell_padding = 7),\n          columns = list(\n          colors_weighted_opp_shot = colDef(show = FALSE),\n          colors_three_vs_league = colDef(show = FALSE),\n          colors_long2_vs_league = colDef(show = FALSE),\n          image_url = colDef(\n                name = \"\",\n                maxWidth = 50,\n                sortable = FALSE,\n                # render team logos from their image address\n                style = background_img()\n              ),\n          `Opponent Long-Range EFG% vs. League Average` = colDef(\n            align = \"center\",\n            cell = data_bars(initial_table,\n                             text_position = \"outside-base\", \n                             number_fmt = percent,\n                             fill_color_ref = \"colors_weighted_opp_shot\"\n          )),\n          `Opponent 3P% vs. League Average` = colDef(\n            align = \"center\",\n            cell = data_bars(initial_table,\n                             text_position = \"outside-base\", \n                             number_fmt = percent,\n                             fill_color_ref = \"colors_three_vs_league\"\n          )),\n          `Opponent Long 2% vs. League Average` = colDef(\n            align = \"center\",\n            cell = data_bars(initial_table,\n                             text_position = \"outside-base\", \n                             number_fmt = percent,\n                             fill_color_ref = \"colors_long2_vs_league\"\n          )\n          )\n          )\n) %>% \n    add_title(\n    title = reactablefmtr::html('Defensive Mirage Metrics:<br>2021-2022 NBA Season')\n  ) %>% \n  add_subtitle(\n    subtitle = \"Lower %s = More Mirage\",\n    font_size = 20,\n    font_color = '#666666'\n  ) %>% \n  google_font(\"Graduate\")\n\n\n\nDefensive Mirage Metrics:2021-2022 NBA Season\nLower %s = More Mirage\n\n\n\n\n\n The table matches pretty well with our earlier visualization! You can play around with the sorting by clicking on each column title or focus on your favorite team by typing it in the search bar."
  },
  {
    "objectID": "posts/nba_2020_2021_mirage_metrics/index.html#offensive-mirage-metrics-1",
    "href": "posts/nba_2020_2021_mirage_metrics/index.html#offensive-mirage-metrics-1",
    "title": "NBA Mirage Metrics:Looking for the Unsustainable",
    "section": "Offensive Mirage Metrics",
    "text": "Offensive Mirage Metrics\n\n\nCode\nreactable(off_metrics_table,\n          pagination = FALSE,\n          searchable = TRUE,\n          defaultSortOrder = \"desc\",\n          defaultSorted = \"Total Offensive Mirage\",\n          style = list(fontFamily = \"graduate\"),\n          theme = espn(centered = TRUE, header_font_size = 12, \n                       cell_padding = 7),\n          columns = list(\n          colors_weighted_team_shot = colDef(show = FALSE),\n          colors_three_mirage = colDef(show = FALSE),\n          colors_long2_mirage = colDef(show = FALSE),\n          image_url = colDef(\n                name = \"\",\n                maxWidth = 50,\n                sortable = FALSE,\n                # render team logos from their image address\n                style = background_img()\n              ),\n          `Total Offensive Mirage` = colDef(\n      align = 'center',\n      minWidth = 200,\n      cell = data_bars(\n        data = initial_table,\n        fill_color = '#EEEEEE',\n        text_position = 'outside-end',\n        max_value = max(initial_table$`Total Offensive Mirage`),\n        icon = 'circle',\n        icon_color_ref = \"colors_weighted_team_shot\",\n        icon_size = 15,\n        text_color_ref = \"colors_weighted_team_shot\",\n        round_edges = TRUE\n      )),\n      `Offensive Mirage 3` = colDef(\n      align = 'center',\n      minWidth = 200,\n      cell = data_bars(\n        data = initial_table,\n        fill_color = '#EEEEEE',\n        text_position = 'outside-end',\n        max_value = max(initial_table$`Offensive Mirage 3`),\n        icon = 'circle',\n        icon_color_ref = 'colors_three_mirage',\n        icon_size = 15,\n        text_color_ref = 'colors_three_mirage',\n        round_edges = TRUE\n      )),\n      `Offensive Mirage Long 2` = colDef(\n      align = 'center',\n      minWidth = 200,\n      cell = data_bars(\n        data = initial_table,\n        fill_color = '#EEEEEE',\n        text_position = 'outside-end',\n        max_value = max(initial_table$`Offensive Mirage Long 2`),\n        icon = 'circle',\n        icon_color_ref = 'colors_long2_mirage',\n        icon_size = 15,\n        text_color_ref = 'colors_long2_mirage',\n        round_edges = TRUE\n      ))\n          )\n) %>% \n    add_title(\n    title = html('Offensive Mirage Metrics:<br>2021-2022 NBA Season')\n  ) %>% \n  add_subtitle(\n    subtitle = html(\"<i class='fas fa-link'></i> Higher Numbers = More Mirage | <a href='https://www.investopedia.com/terms/z/zscore.asp'>{Metrics are Z-Scored}</a>\"),\n    font_size = 20,\n    font_color = '#666666'\n  ) %>% \n  google_font(\"Graduate\")\n\n\n\nOffensive Mirage Metrics:2021-2022 NBA Season\n Higher Numbers = More Mirage | {Metrics are Z-Scored}\n\n\n\n\n\n Looking at the other end of the mirage spectrum, the Memphis Grizzlies already great-looking offense in 2021-2022 might have been held by bad luck. Counting on them to regress offensively in 2022-2023 seems like a bad bet.   On the programming side: The conditional formatting and “visualizations within tables” capabilities unlocked by reactablefmtr are fantastic. I really like gt for table building, and if I want something interactive I think I’ll default to reactablefmtr."
  },
  {
    "objectID": "posts/2022_11_21_stable_diffusion_person_detection/index.html",
    "href": "posts/2022_11_21_stable_diffusion_person_detection/index.html",
    "title": "Detecting Stable Diffusion Generated People",
    "section": "",
    "text": "AI Can Generate Realistic Looking Faces\nthispersondoesnotexist.com blew everyone away when it first launched in 2019. The website would generate a brand new,1 entirely fabricated person each time you refreshed.     The site used GAN neural networks, and provided code templates for generating your own fake people. Some folks pointed out at the time that providing these code templates could have negative consequences.  \n\n\nNegative Side Effects Abound\nFor example, a network of bots using GAN-generated pictures boosted tweets by a pro-secessionist candidate for lieutenant governor in Texas. And that’s far from the only swarm of bots that looked more like real people by using GAN generated faces.   While these GAN-generated faces look realistic, they have some telltale visual cues that can help distinguish them from genuine photos. For example, GAN-generated faces tend to render the eyes in the exact same position. So while they might be tricky to spot, we’ve gotten better at screening for them.2   Enter Stable Diffusion. \n\n\nThe Potential for Negative Side Effects Only Increases with Stable Diffusion\nIn order to create a lot of faces using a GAN, you had to either manually refresh thispersondoesnotexist.com a bunch of times or know how to code. Generating realistic looking faces using Stable Diffusion is much simpler.  If you haven’t heard of Stable Diffusion, it’s a AI model that can convert text prompts like “A cute penguin in front of a giant stack of pancakes, shot on iPhone” into an image like this.      You can also write other kinds of prompts3 that generate realistic looking people. There are few, if any, telltale visual cues that the images were generated by Stable Diffusion.  This person does not exist      Neither does this person      And they don’t either.    \n\n\nI Built and Deployed a Model to Detect Whether People Were Generated by Stable Diffusion\nYou can find the deployed model here. It predicts all of the example images correctly,4 and the model has 93% out-of-sample accuracy with an out-of-sample F1 score of 0.88.     You can test the model with any real or Stable-Diffusion generated images you’d like using the deployed model. Please send interesting model successes + failures to me on Twitter or Mastodon!   This is an initial proof-of-concept, so please don’t use this as part of any production products. If you’re interested in building on this idea I’d love to hear from you!\n\n\nHow Did You Build This Model?\nI had a lot of fun building this model using Python, PyTorch, and the fastai wrapper. I got to do a lot of interesting work with APIs, loops, and query optimization.   In huge contrast to most of my projects, I’m not going to publicly share my code. I don’t want to provide a direct blueprint for how to programmatically generate a lot of realistic-looking fake people. I’m kind of bummed, because I think it’s some of the best Python programming I’ve done. And I still think it’s the right thing to do.  I understand that folks have a variety of opinions about this, and I think the potential harms outweigh any potential benefits.5  If you want to get a sense of how I generally approached my model-building, I’d recommend you check out Practical Deep Learning for Coders.\n\n\nConclusion\nI think Stable Diffusion is a powerful resource, and I think we need to think carefully about how to wield that power. Building models that can help detect whether an image was generated by Stable Diffusion is not a silver bullet answer. I think pervasive believable yet false imagery is a problem that far exceeds any one technical solution.   And as we grapple with the proliferation of models like Stable Diffusion, having some technical tools like this model in our toolbelt feels like a good bet.\n\n\n\n\n\nFootnotes\n\n\nOr almost brand new, if you refresh the site enough you definitely get repeats↩︎\nThough newer generations of GAN-generated faces will likely make them even harder to detect, see https://nvlabs.github.io/stylegan3/↩︎\nWhich I won’t be sharing here, more on that later!↩︎\nHuge shout out to HuggingFace spaces + Gradio for making such a great interface for push-button model deployments↩︎\nEspecially since we know people have used open-source fake people generators for ill already, the risk isn’t hypothetical!↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rigorous Data Science, Translated for Humans",
    "section": "",
    "text": "Rust\n\n\nPython\n\n\nSQL\n\n\nML\n\n\nBest Practices\n\n\n\n\nA Rust-based command line tool to check for ML best practices\n\n\n\n\n\n\nJun 19, 2024\n\n\nMichael Mullarkey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nTrust and Safety\n\n\nPython\n\n\nStable Diffusion\n\n\n\n\nA Deployed Proof-of-Concept\n\n\n\n\n\n\nNov 21, 2022\n\n\nMichael Mullarkey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrust and Safety\n\n\nPython\n\n\nTwitter\n\n\n\n\nAn Initial Investigation\n\n\n\n\n\n\nNov 13, 2022\n\n\nMichael Mullarkey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDuckDB\n\n\nPython\n\n\nTwitter\n\n\n\n\nA Fun Way to Do In-Memory Data Exploration\n\n\n\n\n\n\nNov 9, 2022\n\n\nMichael Mullarkey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCase Study\n\n\nStakeholders\n\n\n\n\nCreating an Interactive, Participatory System\n\n\n\n\n\n\nOct 26, 2022\n\n\nMichael Mullarkey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nQuarto\n\n\nReport-Making\n\n\n\n\nCreate Ultra-Parameterized Reports Disguised as Custom Reports with Quarto and Mustache\n\n\n\n\n\n\nOct 25, 2022\n\n\nMichael Mullarkey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nnba\n\n\n\n\nLooking for the Unsustainable\n\n\n\n\n\n\nOct 17, 2022\n\n\nMichael Mullarkey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]